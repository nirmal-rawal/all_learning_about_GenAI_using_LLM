{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4121ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326557d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ollma mistral\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "current_time = datetime.datetime.now().date()\n",
    "if current_time< datetime.date(2024, 1, 1):\n",
    "    llm_model=\"The current date is before January 1, 2024. Exiting.\"\n",
    "else:\n",
    "    llm_model=\"model is ollma mistral\"\n",
    "    \n",
    "print(llm_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754c91bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3480\\3024412389.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  llm = OllamaEmbeddings(model=\"mistral\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "llm = OllamaEmbeddings(model=\"mistral\")\n",
    "loader =PyPDFLoader(\"research.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5527f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b39e344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x1f033eadaf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd7009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1f0352dad20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb=Chroma.from_documents(\n",
    "    \n",
    "    embedding=llm,\n",
    "    persist_directory=\"chroma_db_for_chat\",\n",
    "    collection_name=\"research_collection\"\n",
    ")\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735317df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecf92835-d4bf-400e-ab7d-8716c82c7722',\n",
       " 'd5084c64-e4cb-4c63-ac5a-ce39f56f1652',\n",
       " 'edfe7a0a-6660-4d6c-a46f-71563b7e936a',\n",
       " 'da731837-53bd-4c3c-b554-d8ea623f1a76',\n",
       " 'e0d27176-0661-452b-843c-af276b30e82e',\n",
       " '9f5f9287-9719-4c42-a243-bd085049770a',\n",
       " 'd4485d49-b55c-4cbb-a945-436459211bde',\n",
       " 'd4d8a6e0-dd74-4c85-b65e-77b7d2177810',\n",
       " '4c7aa973-525d-49ae-b2b3-5724346475ab',\n",
       " 'd9e0ea25-0404-4278-8f0e-a7d58689001d',\n",
       " 'd9b35fa1-3fe9-4129-9c59-a4c6243ce1ab',\n",
       " '9cd523fb-b495-46ed-b262-b06347b0b471',\n",
       " 'a7c5914a-50d5-4381-800d-1177738dc332',\n",
       " '92167efa-4df9-4070-b70b-cc9e3255e9f8',\n",
       " 'bb75def1-d776-44f0-abf9-2c8c797339fc',\n",
       " 'dd1fc95f-80a3-45d1-a5d9-003277878468',\n",
       " '6b3efb55-056d-4307-a2ad-3b99450cd72a',\n",
       " '41c089b3-18da-4f4f-a039-d5348640ec94',\n",
       " '50b9d882-a16b-419c-ad41-7c7d21ea3800',\n",
       " '3fa46db7-2d47-451a-b1dc-7c48f32b43c1',\n",
       " '8df7021a-5cfd-47e2-8b1f-2bc644e5da9d',\n",
       " '21a4a993-81de-45aa-a4f5-3d122eb0177c',\n",
       " '3b38d163-f240-46ff-8f39-9a4c6a40a941',\n",
       " '6b964658-1731-4023-9957-abef1d2e2b00',\n",
       " '380c8175-aa5a-4856-937e-8b9f7964bf7a',\n",
       " '5441a875-cf04-4864-bafd-8eacc46d4b5d',\n",
       " '02b51c22-5268-43dc-adc8-44ab6fdb952f',\n",
       " '28027fa6-5191-425c-a43f-75f839578300']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.add_documents(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581e189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4ab5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3480\\3619756395.py:4: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  model.predict(\"Hello world!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello there! It's nice to meet you. How can I assist you today?\\n\\nHere in this chat, we can discuss a wide range of topics such as programming, mathematics, science, history, literature, and more. If you have any specific questions or if you need help with something, feel free to ask! I'm here to help. ðŸ˜Š\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"mistral\", temperature=0)\n",
    "model.predict(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de49c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3480\\205835925.py:18: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, probability is a common topic in many classes, particularly in mathematics and statistics. It involves the study of random events and their likelihoods.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "question = \"Is probability a class topic?\"\n",
    "qa_chain = RetrievalQA.from_chain_type(model,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9481e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3480\\3824428362.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\",\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c33a163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9384dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24f9c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the provided context, it appears that the data presented is related to machine learning, specifically deep learning, and sign language recognition. However, the context does not explicitly mention \"probability\" as a class topic. It\\'s possible that probability concepts might be used in the background of these studies (for example, in understanding the performance of the models), but it\\'s not clear from the provided information whether probability is a specific focus or topic of study in this context.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b353d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8946ccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To study Machine Learning, particularly Deep Learning, and Sign Language Recognition, you would typically need the following prerequisites:\\n\\n1. Strong foundation in Mathematics, including Linear Algebra, Calculus, Probability, and Statistics.\\n2. Programming skills, preferably in a language commonly used for Machine Learning such as Python or R. Familiarity with libraries like NumPy, Pandas, TensorFlow, PyTorch, or Keras would be beneficial.\\n3. Knowledge of basic Machine Learning algorithms and concepts, such as Supervised Learning, Unsupervised Learning, Reinforcement Learning, Regression, Classification, Clustering, etc.\\n4. Understanding of Deep Learning concepts, including Neural Networks, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and other deep learning architectures.\\n5. Familiarity with Data Preprocessing techniques, such as Normalization, Standardization, Feature Extraction, etc.\\n6. Knowledge of specific domains like Sign Language Recognition would require understanding the basics of Sign Languages, their grammar, and phonology.\\n7. Experience working with real-world datasets, preferably in the domain of Sign Language Recognition, to gain practical skills.\\n8. Familiarity with research methodologies and ability to read and understand academic papers related to Machine Learning, Deep Learning, and Sign Language Recognition.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630e7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
