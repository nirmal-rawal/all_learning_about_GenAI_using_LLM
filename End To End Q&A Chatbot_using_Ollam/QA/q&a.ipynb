{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16534adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffa0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ollma mistral\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "current_time = datetime.datetime.now().date()\n",
    "if current_time< datetime.date(2024, 1, 1):\n",
    "    llm_model=\"The current date is before January 1, 2024. Exiting.\"\n",
    "else:\n",
    "    llm_model=\"model is ollma mistral\"\n",
    "    \n",
    "print(llm_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b91783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "docs = PyPDFLoader(\"research.pdf\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a0b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4424da18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Proceedings of 15th IOE Graduate Conference\\nPeer Reviewed\\nYear: 2024 Month: May Volume: 15\\nISSN: 2350-8914 (Online), 2350-8906 (Print)\\nNepali Sign Language Letter Detection and Finger Spelling Using\\nMediapipe and CNN\\nGuptaraj Shrestha a, Nishan Thing b, Prajita Dhakal c, Prasanga Dahal d, Pukar Karki e, Manoj\\nKumar Guragai f\\na,b,c,d,e,f Department of Electronics and Computer Engineering, Purwanchal Campus, IOE, TU, Nepal\\n a 076bct034@ioepc.edu.np , b 076bct052@ioepc.edu.np , c 076bct057@ioepc.edu.np , d 076bct058@ioepc.edu.np , e pukar@ioepc.edu.np , f\\nmanojkguragai@ioepc.edu.np\\nAbstract\\nThis paper describes the development of a machine learning model to translate Nepali Sign Language (NSL) gestures into\\ncorresponding Nepali text format. The system utilizes computer vision and deep learning techniques, specifically a Convolutional\\nNeural Network (CNN) model trained on a dataset of over 2,500 images per label with total of 50 labels. The training accuracy was'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Neural Network (CNN) model trained on a dataset of over 2,500 images per label with total of 50 labels. The training accuracy was\\n99%, whereas the validation accuracy was 87.78%. Training loss settled at 1.18%, and validation loss settled at 8.258%. A dropout\\nlayer and early stopping function were introduced, and the model was trained for 50 epochs. The model achieved training accuracy\\nof 99.84% and validation accuracy of 99.80%. Similarly, model Training Loss was 0.6% and Validation Loss was 1.16%. The\\nAccuracy curve showed that the both validation and training accuracy gradually increased to 90% for 10 epochs and became steady.\\nSimilarly,in Loss curve both validation and training loss gradually decreased to 4% over the course of 10 epochs and stabilized. A\\nClassification table was created using 20% of total dataset with 500 for each label. Model performance was exceptional for most of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Classification table was created using 20% of total dataset with 500 for each label. Model performance was exceptional for most of\\nthe labels achieving precision, recall and F1-score close to 1. However,for some labels ,model performance was lower in terms of\\nprecision (less than 0.98). The overall accuracy of model was 0.99 describing that model perform well on the entire dataset. The\\ntrained model was integrated into a user-friendly web application along with the logic for finger spelling to verify and validate the real\\nlife use case of the research.\\nKeywords\\nNepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe\\n1. Introduction\\nSign language is an expressive form of communication used\\nby individuals who are deaf or hard of hearing. It allows them\\nto convey thoughts, ideas, and emotions through manual\\ngestures, facial expressions, and body movements. However,\\ndeaf individuals often encounter significant barriers in their'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='to convey thoughts, ideas, and emotions through manual\\ngestures, facial expressions, and body movements. However,\\ndeaf individuals often encounter significant barriers in their\\ndaily interactions, primarily due to the difficulty of\\ncommunicating with those who do not understand sign\\nlanguage.\\nThere are numerous sign languages, such as American Sign\\nLanguage, Indian Sign Language, Nepalese Sign Language, and\\nso on. The signs used in these sign languages are not all the\\nsame. In our country, Nepal, various organizations and schools\\nhave been assisting deaf people to learn Nepali sign language.\\nUnderstanding the importance of connecting the deaf and\\nhearing communities, multiple technologies aimed at\\nimproving communication using Nepalese Sign Language for\\npersons who are deaf or hard of hearing were studied. It was\\nfound that there weren’t any specialized sources online\\nregarding Nepalese Sign Language (NSL). As a result, we\\naimed to create a model that would translate the NSL into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='found that there weren’t any specialized sources online\\nregarding Nepalese Sign Language (NSL). As a result, we\\naimed to create a model that would translate the NSL into\\ntextual output. The user will provide input via webcam, and\\nthe model can detect the hand gesture and output the\\nword/alphabet that the user provided as input to the model.\\nThis paper shows a model that can detect 47 Nepali Alphabets,\\n2 symbols, and one blank. The paper proposes the use of a\\nConvolution Neural Network (CNN). The paper present the\\nuse of Google’ s MediaPipe which is a Framework for building\\nmachine learning pipelines. With the help of MediaPipe Hand\\nModel Model, detect hand region and extract keypoints from\\nthe hands.\\n2. Literature Review\\nSign language is a crucial communication mode for the deaf\\nand hard-of-hearing community. Automatic sign language\\nrecognition (SLR) systems have the potential to bridge the\\ncommunication gap between these communities and the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='and hard-of-hearing community. Automatic sign language\\nrecognition (SLR) systems have the potential to bridge the\\ncommunication gap between these communities and the\\nhearing world. This review focuses on recent advancements in\\nvideo-based SLR systems that leverage deep learning\\ntechniques, particularly Convolutional Neural Networks\\n(CNNs) and Long Short-Term Memory (LSTM) networks.\\nRecent literature in sign language recognition highlights a\\ntransformative shift towards deep learning methodologies,\\nparticularly evident in a pivotal study on Nepali Sign\\nLanguage [ 1]. Deep learning is applied for both motion\\ndetection and detailed exploration of gestures, extracting\\nspatial and temporal features. Two approaches are explored:\\none using CNN and RNN, and another using CNN and Vision\\nTransformer. The latter outperforms in accuracy, emphasizing\\nthe growing importance of deep learning in enhancing sign\\nlanguage recognition systems. These advancements'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Transformer. The latter outperforms in accuracy, emphasizing\\nthe growing importance of deep learning in enhancing sign\\nlanguage recognition systems. These advancements\\ncontribute to improved communication accessibility for\\nindividuals relying on sign language.\\nPages: 166 – 170'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='Proceedings of 15th IOE Graduate Conference\\nFigure 1: System Block Diagram\\nExpanding on this foundation, another significant\\ncontribution emerged in the form of a novel method for\\ncharacter identification in American Sign Language, utilizing\\nConvolutional Neural Networks (CNNs) [2]. The research not\\nonly introduced an innovative approach but also emphasized\\nthe indispensable role CNNs play in the realm of sign\\nlanguage recognition, particularly in the context of character\\nidentification. The implications of this study extend beyond\\nAmerican Sign Language, shaping the trajectory of gesture\\nrecognition in a broader spectrum.\\nDiversifying the research landscape, a study concentrating on\\nIndian Sign Language harnessed the capabilities of MediaPipe\\nHolistic to identify movements and facilitate their conversion\\ninto text or voice, effectively bridging the communication gap\\nbetween sign language and other modes of expression [ 3].\\nNoteworthy is the emphasis on discerning between static and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='into text or voice, effectively bridging the communication gap\\nbetween sign language and other modes of expression [ 3].\\nNoteworthy is the emphasis on discerning between static and\\ndynamic signs, revealing the superior performance of Long\\nShort-Term Memory (LSTM) models in tracking dynamic\\nphrases, while CNNs demonstrate proficiency in capturing\\nstatic characters.\\nIn parallel, a groundbreaking project introduced a real-time\\nsign language detection system by synergizing Convolutional\\nNeural Networks (CNNs) and Recurrent Neural Networks\\n(RNNs) [ 4]. The study, titled \"Recognizing Sign Language\\nGestures from Video Sequences,\" showcased the synergistic\\neffectiveness of these networks in real-time recognition,\\nsetting the stage for practical applications in assistive\\ntechnology.\\nLastly, Research Journal of Engineering and Technology The\\nproposed system integrates Convolutional Neural Networks\\n(CNNs) for visual feature extraction and Long Short-Term'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='technology.\\nLastly, Research Journal of Engineering and Technology The\\nproposed system integrates Convolutional Neural Networks\\n(CNNs) for visual feature extraction and Long Short-Term\\nMemory (LSTM) networks for understanding the order of\\nsigns [5]. The primary objective was to convert Nepali Sign\\nLanguage into written text. The system captures sign images\\nthrough a camera and employs a CNN to analyze them. Initial\\ntraining concentrated on a limited set of signs (5 and 7), with\\nbetter accuracy achieved in the smaller set. Despite promising\\noutcomes, the study acknowledges constraints, such as a\\nrestricted sign vocabulary and reliance on red gloves during\\ntesting, posing challenges for practical use. In essence, this\\nresearch represents a crucial step in utilizing advanced neural\\nnetworks to enhance communication between the deaf and\\nhearing communities in Nepal.\\nIn summation, the collective body of research signifies the\\nascendance of deep learning, particularly the integration of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='hearing communities in Nepal.\\nIn summation, the collective body of research signifies the\\nascendance of deep learning, particularly the integration of\\nCNNs and LSTMs, in the realm of sign language recognition.\\nThese studies, encompassing diverse aspects from\\nunderstanding intricate gestures to real-time detection, depict\\na vibrant landscape of advancements that are actively shaping\\nthe future of communication for the hearing-impaired. The\\nintegration of deep learning not only ensures more accurate\\nand responsive gesture recognition systems but also holds the\\npromise of seamlessly incorporating sign languages into\\nmainstream communication technologies.\\n3. Methodology\\n3.1 Data Collection\\nImage datasets were captured using 4 different laptops for 50\\nlabels with an image resolution of 540 x 540 pixels. With the\\nhelp of the OpenCV library, the image was captured for about\\n2500 images per label; in total, 1,25,000 image datasets were'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='labels with an image resolution of 540 x 540 pixels. With the\\nhelp of the OpenCV library, the image was captured for about\\n2500 images per label; in total, 1,25,000 image datasets were\\ncollected. These captured images were not the final dataset,\\nthe aim was to create a dataset containing Hand landmarks\\nfor these images. The sample image of the Captured Image is\\nshown in Figure 2.\\nFigure 2: Original Image\\n3.1.1 Cropping Capture Image\\nMediaPipe Hands Model used to crop the image, which is\\ndeveloped by Google to utilizes an ML pipeline consisting of\\n167'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN\\nmultiple models working together: A palm detection model\\nthat operates on the full image and returns an oriented hand\\nbounding box and a hand landmark model that operates on\\nthe cropped image region defined by the palm detector and\\nreturns high-fidelity 3D hand keypoints[6] as shown in Figure\\n3.\\nThe image with resolution 540 x 540 px was passed through\\nthe MediaPipe hand model with parameter static_image\\nmode = True, min_detection_confidence=0.3, and\\nmax_num_hands=1 to detect the palm area from the captured\\nimage. Before being fed to the Hand landmark model, the\\nimage is converted into RBG format. Using this model, a set of\\n21 key points representing various landmarks on the hand was\\nobtained, such as fingertips, knuckles, and the palm. Based on\\nthe Hand Landmark index 9 i.e MIDDLE FINGER MCP and\\nHand Landmark index 12 i.e. MIDDLE FINGER TIP , the\\noriginal image was cropped. The size of the cropped image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='the Hand Landmark index 9 i.e MIDDLE FINGER MCP and\\nHand Landmark index 12 i.e. MIDDLE FINGER TIP , the\\noriginal image was cropped. The size of the cropped image\\nwas set to 200 x 200 pixels, determined by the original\\ndimensions of the image. These cropped images contain only\\nthe image of one palm or hand, which is in BGR form. The\\nsample of the cropped image is shown in figure 4. This\\ncropped image contained only the palm area image not a\\nHand Keypoints.\\nFigure 3: Hand Landmark\\n3.1.2 Hand Landmark Image Drawing\\nThe cropped image was converted into RGB form and fed to\\nMediaPipe Hand model to extract key points of hand from the\\ncropped images. Based on the coordinates of the extracted key\\npoints, the coordinates of landmarks were drawn on the plain\\nblack background. The drawn hand landmark image had the\\nsame shape as the cropped images i.e. 200 x 200 pixels. The\\nlandmark image was saved in grayscale format. The sample\\nimage of the Landmark image is shown in figure 5. This Hand'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='same shape as the cropped images i.e. 200 x 200 pixels. The\\nlandmark image was saved in grayscale format. The sample\\nimage of the Landmark image is shown in figure 5. This Hand\\nLandmark Image was the final Dataset. Each Character of the\\nNepali Alphabet was labeled as shown in figure 6.\\nFigure 4: Cropped Image\\n Figure 5: Landmark Image\\nFigure 6: Dataset Label\\n3.2 Data Pre-Processing\\nDuring pre-processing, the dataset image was converted into\\na NumPy array and reshaped to 200 x 200 pixels. The pixel\\nvalues lie within a range of 0 to 1 in this preprocessed image\\ndata, which comprises a 4D NumPy array.\\n3.3 Training CNN Model\\nThe training process focused on instructing the model to\\nidentify Nepali Sign Language (NSL) signs from video frames\\nof gestures. Initially, 125,000 total dataset were divided into\\ntraining and validation sets with an 80-20 ratio using the split\\nfolders library i.e. Training set consists of 100,000 dataset and\\nthe Validation or Test set consists of 25,000 dataset.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='training and validation sets with an 80-20 ratio using the split\\nfolders library i.e. Training set consists of 100,000 dataset and\\nthe Validation or Test set consists of 25,000 dataset.\\nImageDataGenerator was employed with an input size of\\n200*200, class mode set to ‘categorical’ , color mode set to\\n‘grayscale’ , and a batch size of 128. This was utilized to convert\\nthe data into the necessary format and normalize the dataset\\nusing the rescale parameter.\\nIn order to include all required layers, the model’ s architecture\\ncontained a sequential Keras model. At first, features were\\nextracted from the video frame using Conv2D layers with a 3x3\\nkernel and the ‘relu’ activation function. The MaxPooling2D\\nlayers with a 2x2 filter were applied before each Conv2D layer,\\nallowing for a reduction in both image size and complexity. To\\nreduce overfitting, dropout layers with a 0.4 dropout rate were\\nalso included. To improve the model’ s compatibility, these'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='allowing for a reduction in both image size and complexity. To\\nreduce overfitting, dropout layers with a 0.4 dropout rate were\\nalso included. To improve the model’ s compatibility, these\\nthree layers were replicated. The 4D data was then\\ntransformed into 1D using a flatten layer. ‘Relu’ activation\\nfunctions were used in two Dense layers, with 256 and 64\\nchannels, respectively. The final classification of NSL signs\\nwas given to a Dense layer with 50 output channels and\\nsoftmax activation.\\nTo compile the model, the Adam optimizer with a default\\nlearning rate of 0.001 was employed. Other optimizers, such\\nas SGD with a learning rate of 0.01 and RMSProp with a\\nlearning rate of 0.001, were also tested, but Adam was found to\\nbe the best fit for the model. To find the optimal parameter,\\nthe learning rate of Adam was further revised, with values\\nranging from 0.0001, 0.002, and 0.0002, but the default Adam\\nsetting turned out to be the most accurate. For the loss'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='the learning rate of Adam was further revised, with values\\nranging from 0.0001, 0.002, and 0.0002, but the default Adam\\nsetting turned out to be the most accurate. For the loss\\nfunction, Categorical Cross-Entropy was utilized. Additionally,\\naccuracy was used as a statistic to evaluate how well the\\nmodel predicted NSL signals. The model was then trained\\nusing the fit function, which was used to select the number of\\nepochs and incorporate the validation set to measure\\nperformance throughout the process. The validation loss was\\n168'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='Proceedings of 15th IOE Graduate Conference\\nanalyzed using the EarlyStopping function, which was used to\\nend the fitting process when suitable. Finally, the accuracy of\\nthe model was evaluated to measure its effectiveness.\\n3.4 Model Integration with Logic for Finger Spelling\\nA straightforward approach was developed to combine letters\\ndetected by a CNN model for Nepali finger spelling. Letters\\nare stored in an array, and once the array is full and contains at\\nleast two letters, they are processed to form a complete word.\\nThe system differentiates between consonants and vowels,\\napplying specific logic based on their combinations.\\nVowel-vowel pairs are simply joined, while consonant-vowel\\ncombinations involve replacing the vowel with its\\ncorresponding symbol as shown in figure 7 and joining it with\\nthe consonant. In both vowel-consonant and\\nconsonant-consonant combinations, the initial part (or the\\nfirst letter in the array) remains unchanged. The process then'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='the consonant. In both vowel-consonant and\\nconsonant-consonant combinations, the initial part (or the\\nfirst letter in the array) remains unchanged. The process then\\nfocuses on modifying the second consonant based on the\\nfollowing letter (third letter in the array for any of the above\\ncombinations). This logic ensures proper Nepali word\\nformation by considering the unique characteristics of\\nconsonant-vowel interactions in the language.\\nFigure 7: Vowel and Their Symbol\\n4. Results and Discussion\\n4.1 Result\\n4.1.1 Accuracy and Loss Curve\\nThe accuracy curve shown in figure 8 rapidly increases to\\nnearly 100%, indicating how well the model fits the training set\\nof data. However, the validation accuracy curve peaks around\\n90% after an initial sharp rise. This indicates that the model\\ndoes not get any more accurate with more training epochs,\\nbut it does generalize to unknown data very well initially.\\nFigure 8: Accuracy Curve\\n Figure 9: Loss Curve'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='does not get any more accurate with more training epochs,\\nbut it does generalize to unknown data very well initially.\\nFigure 8: Accuracy Curve\\n Figure 9: Loss Curve\\nSimilarly, the Loss Curve shown in figure 9 drops sharply to\\nnear zero within the first few epochs. This confirms the model\\nfits the training data extremely well after initial learning.\\nHowever, the validation loss curve initially decreases and then\\npeaks at a higher value compared to the training loss. This\\nindicates the model is being overfitted to the training data.\\nThis limits the model’ s ability to generalize and perform well\\non new, unseen data from the validation set.\\n4.1.2 Classification Table\\nprecision recall f1-score support\\n0 0.98 1.00 0.99 500\\n1 0.97 0.99 0.98 500\\n2 0.99 0.93 0.96 500\\n3 0.99 1.00 0.99 500\\n4 1.00 0.99 0.99 500\\n5 1.00 1.00 1.00 500\\n6 1.00 1.00 1.00 500\\n7 1.00 1.00 1.00 500\\n8 1.00 0.99 0.99 500\\n9 0.99 0.99 0.99 500\\n10 0.98 1.00 0.99 500\\n11 0.99 1.00 1.00 500\\n12 1.00 1.00 1.00 500'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='4 1.00 0.99 0.99 500\\n5 1.00 1.00 1.00 500\\n6 1.00 1.00 1.00 500\\n7 1.00 1.00 1.00 500\\n8 1.00 0.99 0.99 500\\n9 0.99 0.99 0.99 500\\n10 0.98 1.00 0.99 500\\n11 0.99 1.00 1.00 500\\n12 1.00 1.00 1.00 500\\n13 0.99 0.98 0.98 500\\n14 0.98 0.98 0.98 500\\n15 0.99 0.98 0.99 500\\n16 0.99 1.00 1.00 500\\n17 0.98 1.00 0.99 500\\n18 1.00 0.99 0.99 500\\n19 0.96 0.99 0.97 500\\n20 1.00 1.00 1.00 500\\n21 0.97 1.00 0.99 500\\n22 0.99 1.00 0.99 500\\n23 1.00 1.00 1.00 500\\n24 0.99 0.96 0.98 500\\n25 1.00 0.99 0.99 500\\n26 1.00 1.00 1.00 500\\n27 0.99 0.99 0.99 500\\n28 1.00 1.00 1.00 500\\n29 0.97 0.99 0.98 500\\n30 0.99 0.99 0.99 500\\n31 1.00 1.00 1.00 500\\n32 1.00 0.99 0.99 500\\n33 1.00 1.00 1.00 500\\n34 1.00 1.00 1.00 500\\n35 1.00 0.97 0.98 500\\n36 0.99 1.00 0.99 500\\n37 1.00 1.00 1.00 500\\n38 0.97 1.00 0.99 500\\n39 0.98 1.00 0.99 500\\n40 1.00 1.00 1.00 500\\n41 1.00 1.00 1.00 500\\n42 1.00 1.00 1.00 500\\n43 1.00 0.99 1.00 500\\n44 1.00 1.00 1.00 500\\n45 1.00 0.97 0.98 500\\n46 0.99 0.98 0.99 500\\n47 1.00 1.00 1.00 500\\n48 0.98 0.97 0.97 500'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='40 1.00 1.00 1.00 500\\n41 1.00 1.00 1.00 500\\n42 1.00 1.00 1.00 500\\n43 1.00 0.99 1.00 500\\n44 1.00 1.00 1.00 500\\n45 1.00 0.97 0.98 500\\n46 0.99 0.98 0.99 500\\n47 1.00 1.00 1.00 500\\n48 0.98 0.97 0.97 500\\n49 0.98 0.98 0.98 500\\naccuracy 0.99 25000\\nmacro avg 0.99 0.99 0.99 25000\\nweighted avg 0.99 0.99 0.99 25000\\nA classification report is a comprehensive summary of the\\nperformance of a classification algorithm on a dataset. It\\nprovides various metrics for each class, helping to evaluate the\\nmodel’ s precision, recall, F1 score, and support. The\\nclassification Table of our model is shown in the above Table.\\n169'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN\\n4.1.3 Output\\nFigure 10: Hand Landmark Detection Steps\\nFigure 11: Output\\nFigure 11 shows the real time prediction of a letter and joining\\nof each letter to form a word at last.\\nFigure 12: Success Case\\nHand gesture is detected and landmark is successfully drawn,\\nbut only when the hand is shown to the camera at the right\\nangle, at about 60 cm from the camera, the hand must be held\\nstable, and the signs must only be given according to prompts\\ndisplayed on the screen.\\nFigure 13: Change in\\nAngle\\n Figure 14: Low Light\\nHand might not be detected properly if it’ s too close to the\\ncamera or if it’ s not facing directly towards the camera.\\nChanges in lighting can also affect detection. In case of wrong\\nhand gesture input, it might give the wrong output.\\n5. Conclusion\\nThe majority of the deaf community faces deprivation of basic\\nservices due to communication barriers with the hearing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='hand gesture input, it might give the wrong output.\\n5. Conclusion\\nThe majority of the deaf community faces deprivation of basic\\nservices due to communication barriers with the hearing\\ncommunity. This paper introduced a model designed to\\npredict Nepali Sign language characters. Mediapipe and\\nOpenCV were used for Real-time data collection.\\nModel-building strategies like transfer learning and different\\nneural network architectures were examined and a simple\\nCNN model which contained ConV2D, MaxPolling layer,\\nFlatten layer, and Dense layer, was ultimately chosen.\\nOptimizers like ‘ Adam’ , ‘RMSProp’ , and ‘SGD’ were examined,\\nleading to the selection of Adam optimizers. A graph was\\nanalyzed by changing the learning rate to 0.0001, 0.002, 0.0002,\\netc. However, the default ‘ Adam’ worked accurately for the\\nmodel. At first, Relu activation function was used in all layers\\nincluding the output Dense layer. The Accuracy and Loss\\ncurve were steady. Finally Softmax activation function was'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='model. At first, Relu activation function was used in all layers\\nincluding the output Dense layer. The Accuracy and Loss\\ncurve were steady. Finally Softmax activation function was\\nused which provided the appropriate graph with accuray of\\n99%˙The model’ s advancement to produce words directly\\ninstead of only characters is a crucial step toward its future\\ndevelopment. The model needs to be improved for real-time\\nprocessing speed in order for its use to be expanded beyond\\nprimary school students. Furthermore, adding extra features\\nlike captioning for sign language videos can significantly\\nimprove inclusion and accessibility. All of these improvements\\nwork together to improve the model’ s performance and\\nincrease the range of educational levels and communication\\nmodalities in which it can be used.\\nAcknowledgments\\nThe authors extend their heartfelt gratitude to the Department\\nof Electronics and Computer Engineering, Purwanchal\\nCampus for the unwavering support, guidance, and\\nencouragement.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Acknowledgments\\nThe authors extend their heartfelt gratitude to the Department\\nof Electronics and Computer Engineering, Purwanchal\\nCampus for the unwavering support, guidance, and\\nencouragement.\\nReferences\\n[1] S. Ligal and D. S. Baral. Nepali sign language gesture\\nrecognition using deep learning. In Proceedings of the 12th\\nIOE Graduate Conference, volume 12, October 2022.\\n[2] Sarfaraz Masood, Harish Chandra Thuwal, and Adhyan\\nSrivastava. American sign language character recognition\\nusing convolution neural network. In Smart Computing\\nand Informatics, pages 403–412. Springer, 2018.\\n[3] Kaushal Goyal and Dr. Velmathi G. Indian sign language\\nrecognition using mediapipe holistic. In Proceedings of the\\nVIT, Chennai, India, 2023.\\n[4] Sarfaraz Masood, Adhyan Srivastava, Harish Chandra\\nThuwal, and Musheer Ahmad. Real-time sign language\\ngesture (word) recognition from video sequences using\\ncnn and rnn. In Intelligent Engineering Informatics, pages\\n623–632. Springer, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Thuwal, and Musheer Ahmad. Real-time sign language\\ngesture (word) recognition from video sequences using\\ncnn and rnn. In Intelligent Engineering Informatics, pages\\n623–632. Springer, 2018.\\n[5] D. Mali, R. Mali, S. Sipai, and S. P . Pandey. Nepali sign\\nlanguage translation using convolutional neural network.\\nIn 1st KEC Conference Proceedings, Volume I, September 27\\n2018.\\n[6] MediaPipe. Mediapipe hands documentation, 2024.\\n170')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d8c382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_dic=\"QA/chroma\"\n",
    "model= OllamaEmbeddings(model=\"mistral\")\n",
    "vectordb = Chroma(\n",
    "    embedding_function=model,\n",
    "    persist_directory=persist_dic,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ecd3a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26d1f4aa-0df1-4588-be34-830a9d1b0bff',\n",
       " '7e1e715d-fe7a-45f9-8b59-4eb838363009',\n",
       " '738b844b-77fa-4fc2-b2b4-2c78234c8b66',\n",
       " 'b83aee48-6447-4c88-bb34-047140fa1caa',\n",
       " '325358e2-39e9-4068-bf31-2802952397ea',\n",
       " '5305e133-a306-4824-8881-9c56f873b332',\n",
       " '677ad2a4-7146-4cd9-993e-26000a07ddb8',\n",
       " '1b4bb9d9-3a96-4b54-ad94-06b3903849d0',\n",
       " '34c1f4ef-3ddc-4984-b9f6-af093c6bc956',\n",
       " '86908de8-f04e-404d-8ffa-66ac8340d0ca',\n",
       " '549aa21e-3656-4f0d-9cc1-80725ab9b9b2',\n",
       " '4531616a-ef1c-4efe-9dcc-21d48dafd19d',\n",
       " 'acc67585-95dc-42c3-a582-19f547f2732f',\n",
       " 'fc5e6f91-3096-4c90-bb78-a1c4052b9f94',\n",
       " '844dc923-777d-4777-b805-6a0984e9bd45',\n",
       " '2a9ca18e-4167-4786-9b70-16653e9124fa',\n",
       " 'c58e9b1d-4db1-47cf-8e81-c68c32cb46e0',\n",
       " '1c61931e-1594-423d-867f-c15e88178350',\n",
       " '2fe25c99-4818-4be0-ac67-498198f07d85',\n",
       " 'afa3c9e1-7027-4240-a897-03de94c3cb0f',\n",
       " '182cbc32-649b-4217-b113-1b96b37e68af',\n",
       " 'aa5b7636-0bc2-4ea9-a0e9-96b1ea707f0f',\n",
       " 'e789c230-9ba7-4173-9dc6-f435c9514b76',\n",
       " '99ab26cf-b742-4cdc-b64d-9c8f4964c24f',\n",
       " '1b644c29-81eb-4313-87ad-3ebf93520bb3',\n",
       " '2db632db-f7ee-4872-aab2-5535c4cd7702',\n",
       " 'b19db1be-c584-4628-b1c9-fd58edba7560',\n",
       " 'efe6fd42-9e8b-4e81-9f8c-48992a93ed98']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "def5d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef05708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beda209",
   "metadata": {},
   "source": [
    "## RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68f43c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_23800\\710658220.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"mistral\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b94a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb15d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7714e5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_23800\\4094420968.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae4b5e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the provided context, it appears that the main topics for this class could be:\\n\\n1. Sign Language Recognition: This includes understanding various sign languages, their gestures, and developing systems to recognize these signs using deep learning techniques such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN).\\n\\n2. Deep Learning: This involves studying the principles of deep learning, its applications, and its role in enhancing sign language recognition systems.\\n\\n3. Computer Vision: This topic focuses on teaching how to process and analyze visual data from a video or image, which is crucial for sign language recognition.\\n\\n4. Natural Language Processing (NLP): While not explicitly mentioned in the provided context, NLP could be an indirect part of the class given that it\\'s often used in conjunction with computer vision for understanding and interpreting signs.\\n\\n5. Transformer Models: This topic seems to be specifically mentioned as being important for sign language recognition, suggesting that students will learn about this type of deep learning model.\\n\\n6. Nepali Sign Language (NSL): Given the context mentions \"Nepali sign language gesture recognition using deep learning,\" it\\'s likely that the class also focuses on NSL specifically.\\n\\n7. References and Resources: The provided references suggest that students will be expected to read and understand academic papers related to sign language recognition, deep learning, computer vision, and NLP.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff27d40",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1edbf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0a9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever= vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9969c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how do we find the sing nepali language help to the people and what process are used in that research paper?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d04fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The provided research paper utilizes deep learning techniques, specifically Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), for real-time sign language gesture recognition from video sequences. This helps individuals relying on Nepali Sign Language by enhancing communication accessibility. The process involves training the model on a dataset of sign language gestures, which is then used to recognize and interpret signs in real-time.\\n\\nThanks for asking!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5492b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'trapped': '/False', 'creator': 'LaTeX with hyperref', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2024-08-22T12:54:44+05:45', 'page': 3, 'subject': '14th IOE Graduate Conference', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'page_label': '169', 'source': 'research.pdf', 'moddate': '2024-08-22T12:54:44+05:45', 'total_pages': 5}, page_content='4 1.00 0.99 0.99 500\\n5 1.00 1.00 1.00 500\\n6 1.00 1.00 1.00 500\\n7 1.00 1.00 1.00 500\\n8 1.00 0.99 0.99 500\\n9 0.99 0.99 0.99 500\\n10 0.98 1.00 0.99 500\\n11 0.99 1.00 1.00 500\\n12 1.00 1.00 1.00 500\\n13 0.99 0.98 0.98 500\\n14 0.98 0.98 0.98 500\\n15 0.99 0.98 0.99 500\\n16 0.99 1.00 1.00 500\\n17 0.98 1.00 0.99 500\\n18 1.00 0.99 0.99 500\\n19 0.96 0.99 0.97 500\\n20 1.00 1.00 1.00 500\\n21 0.97 1.00 0.99 500\\n22 0.99 1.00 0.99 500\\n23 1.00 1.00 1.00 500\\n24 0.99 0.96 0.98 500\\n25 1.00 0.99 0.99 500\\n26 1.00 1.00 1.00 500\\n27 0.99 0.99 0.99 500\\n28 1.00 1.00 1.00 500\\n29 0.97 0.99 0.98 500\\n30 0.99 0.99 0.99 500\\n31 1.00 1.00 1.00 500\\n32 1.00 0.99 0.99 500\\n33 1.00 1.00 1.00 500\\n34 1.00 1.00 1.00 500\\n35 1.00 0.97 0.98 500\\n36 0.99 1.00 0.99 500\\n37 1.00 1.00 1.00 500\\n38 0.97 1.00 0.99 500\\n39 0.98 1.00 0.99 500\\n40 1.00 1.00 1.00 500\\n41 1.00 1.00 1.00 500\\n42 1.00 1.00 1.00 500\\n43 1.00 0.99 1.00 500\\n44 1.00 1.00 1.00 500\\n45 1.00 0.97 0.98 500\\n46 0.99 0.98 0.99 500\\n47 1.00 1.00 1.00 500\\n48 0.98 0.97 0.97 500')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4b17e",
   "metadata": {},
   "source": [
    "## RetrievalQA chain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17c7fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    chain_type=\"map_reduce\",\\\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caf170ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\langchain_Models\\End To End Q&A Chatbot_using_Ollam\\chatvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "c:\\langchain_Models\\End To End Q&A Chatbot_using_Ollam\\chatvenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Acer\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain_mr({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7abcfd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the provided texts, there is no explicit mention of how the Nepali sign language research helps people directly. However, both research papers discuss advancements in recognizing and translating Nepali sign language using deep learning (deep learning) and Convolutional Neural Networks (CNN), respectively. These advancements could potentially aid people who are deaf or hard of hearing by improving communication accessibility.\\n\\nTo find more information about how these research findings might help people, you may want to read the full texts of the papers if available. They should provide details on the practical applications and potential benefits of their respective methods for Nepali sign language users.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b940339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Given the additional context provided, it appears that the research paper is focused on developing a system for real-time Nepali Sign Language (NSL) gesture recognition using deep learning techniques, specifically Transformer models. The authors have referenced previous works in American Sign Language (ASL) character recognition and Indian Sign Language (ISL) recognition to support their study.\\n\\nTo help people who use NSL, the process used in this research paper involves collecting video data of NSL gestures, preprocessing the data, and training deep learning models to recognize these gestures. The authors have utilized Transformer models, which outperform other architectures such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), in terms of accuracy.\\n\\nThe research paper aims to develop a system that can accurately recognize NSL gestures in real-time, which could be beneficial for deaf or hard-of-hearing individuals who use NSL as their primary means of communication. The authors have acknowledged the support, guidance, and encouragement they received from the Department of Electronics and Computer Engineering at Purwanchal Campus during their research. They have also referenced several relevant studies on ASL and ISL recognition to provide context for their work (Thuwal & Musheer Ahmad, 2018; Mali et al., 2018). The paper can be found in pages 166 – 170.\\n\\nIn addition, the authors have referenced MediaPipe hands documentation (MediaPipe, 2024) for hand tracking and gesture recognition, which could potentially be used to improve the accuracy of their system. This further emphasizes the importance of deep learning in enhancing sign language recognition systems and improving communication accessibility for individuals relying on sign language.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9c20654",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8c2ce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Based on the provided context, it appears that the focus is primarily on sign language recognition using deep learning techniques such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), rather than on probability theory as a class topic. However, probability concepts might be used in the implementation of these deep learning models for tasks like predicting the likelihood of a certain sign language gesture or word being present in the input data. But without explicit mention of probability as a class topic, it's reasonable to assume that it is not the main focus of the provided context.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a16d127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The provided context does not explicitly state why the prerequisites (knowledge or skills) are needed, but it can be inferred that they are related to understanding the topic of sign language recognition and the deep learning models used for this purpose.\\n\\nThe authors of the referenced papers have used deep learning techniques such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Transformers to improve the accuracy of sign language recognition systems. Therefore, having knowledge about these models and their applications would be beneficial for understanding the context provided.\\n\\nAdditionally, the context mentions a neural network model trained on a dataset with over 2,500 images per label and total of 50 labels. Understanding how to train and evaluate such a model, including concepts like training accuracy, validation accuracy, loss, dropout layer, early stopping function, and epochs, would be important for interpreting the results presented in the context.\\n\\nLastly, the context mentions a classification table created using 20% of the total dataset with 500 images per label. Knowledge about how to create and interpret such tables, as well as understanding the concept of label imbalance (since there are only 50 unique labels in the dataset), would be useful for comprehending the model's performance as described in the context.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18be126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
