{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e787b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proceedings of 15th IOE Graduate Conference\\nPeer Reviewed\\nYear: 2024 Month: May Volume: 15\\nISSN: 2350-8914 (Online), 2350-8906 (Print)\\nNepali Sign Language Letter Detection and Finger Spelling Using\\nMediapipe and CNN\\nGuptaraj Shrestha a, Nishan Thing b, Prajita Dhakal c, Prasanga Dahal d, Pukar Karki e, Manoj\\nKumar Guragai f\\na,b,c,d,e,f Department of Electronics and Computer Engineering, Purwanchal Campus, IOE, TU, Nepal\\n a 076bct034@ioepc.edu.np , b 076bct052@ioepc.edu.np , c 076bct057@ioepc.edu.np , d 076bct058@ioepc.edu.np , e pukar@ioepc.edu.np , f\\nmanojkguragai@ioepc.edu.np\\nAbstract\\nThis paper describes the development of a machine learning model to translate Nepali Sign Language (NSL) gestures into\\ncorresponding Nepali text format. The system utilizes computer vision and deep learning techniques, specifically a Convolutional\\nNeural Network (CNN) model trained on a dataset of over 2,500 images per label with total of 50 labels. The training accuracy was\\n99%, whereas the validation accuracy was 87.78%. Training loss settled at 1.18%, and validation loss settled at 8.258%. A dropout\\nlayer and early stopping function were introduced, and the model was trained for 50 epochs. The model achieved training accuracy\\nof 99.84% and validation accuracy of 99.80%. Similarly, model Training Loss was 0.6% and Validation Loss was 1.16%. The\\nAccuracy curve showed that the both validation and training accuracy gradually increased to 90% for 10 epochs and became steady.\\nSimilarly,in Loss curve both validation and training loss gradually decreased to 4% over the course of 10 epochs and stabilized. A\\nClassification table was created using 20% of total dataset with 500 for each label. Model performance was exceptional for most of\\nthe labels achieving precision, recall and F1-score close to 1. However,for some labels ,model performance was lower in terms of\\nprecision (less than 0.98). The overall accuracy of model was 0.99 describing that model perform well on the entire dataset. The\\ntrained model was integrated into a user-friendly web application along with the logic for finger spelling to verify and validate the real\\nlife use case of the research.\\nKeywords\\nNepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe\\n1. Introduction\\nSign language is an expressive form of communication used\\nby individuals who are deaf or hard of hearing. It allows them\\nto convey thoughts, ideas, and emotions through manual\\ngestures, facial expressions, and body movements. However,\\ndeaf individuals often encounter significant barriers in their\\ndaily interactions, primarily due to the difficulty of\\ncommunicating with those who do not understand sign\\nlanguage.\\nThere are numerous sign languages, such as American Sign\\nLanguage, Indian Sign Language, Nepalese Sign Language, and\\nso on. The signs used in these sign languages are not all the\\nsame. In our country, Nepal, various organizations and schools\\nhave been assisting deaf people to learn Nepali sign language.\\nUnderstanding the importance of connecting the deaf and\\nhearing communities, multiple technologies aimed at\\nimproving communication using Nepalese Sign Language for\\npersons who are deaf or hard of hearing were studied. It was\\nfound that there weren’t any specialized sources online\\nregarding Nepalese Sign Language (NSL). As a result, we\\naimed to create a model that would translate the NSL into\\ntextual output. The user will provide input via webcam, and\\nthe model can detect the hand gesture and output the\\nword/alphabet that the user provided as input to the model.\\nThis paper shows a model that can detect 47 Nepali Alphabets,\\n2 symbols, and one blank. The paper proposes the use of a\\nConvolution Neural Network (CNN). The paper present the\\nuse of Google’ s MediaPipe which is a Framework for building\\nmachine learning pipelines. With the help of MediaPipe Hand\\nModel Model, detect hand region and extract keypoints from\\nthe hands.\\n2. Literature Review\\nSign language is a crucial communication mode for the deaf\\nand hard-of-hearing community. Automatic sign language\\nrecognition (SLR) systems have the potential to bridge the\\ncommunication gap between these communities and the\\nhearing world. This review focuses on recent advancements in\\nvideo-based SLR systems that leverage deep learning\\ntechniques, particularly Convolutional Neural Networks\\n(CNNs) and Long Short-Term Memory (LSTM) networks.\\nRecent literature in sign language recognition highlights a\\ntransformative shift towards deep learning methodologies,\\nparticularly evident in a pivotal study on Nepali Sign\\nLanguage [ 1]. Deep learning is applied for both motion\\ndetection and detailed exploration of gestures, extracting\\nspatial and temporal features. Two approaches are explored:\\none using CNN and RNN, and another using CNN and Vision\\nTransformer. The latter outperforms in accuracy, emphasizing\\nthe growing importance of deep learning in enhancing sign\\nlanguage recognition systems. These advancements\\ncontribute to improved communication accessibility for\\nindividuals relying on sign language.\\nPages: 166 – 170'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader,PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader= PyPDFLoader(\"research.pdf\")\n",
    "documents=loader.load()\n",
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc25f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs =text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df163038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Proceedings of 15th IOE Graduate Conference\\nPeer Reviewed\\nYear: 2024 Month: May Volume: 15\\nISSN: 2350-8914 (Online), 2350-8906 (Print)\\nNepali Sign Language Letter Detection and Finger Spelling Using\\nMediapipe and CNN\\nGuptaraj Shrestha a, Nishan Thing b, Prajita Dhakal c, Prasanga Dahal d, Pukar Karki e, Manoj\\nKumar Guragai f\\na,b,c,d,e,f Department of Electronics and Computer Engineering, Purwanchal Campus, IOE, TU, Nepal\\n a 076bct034@ioepc.edu.np , b 076bct052@ioepc.edu.np , c 076bct057@ioepc.edu.np , d 076bct058@ioepc.edu.np , e pukar@ioepc.edu.np , f\\nmanojkguragai@ioepc.edu.np\\nAbstract\\nThis paper describes the development of a machine learning model to translate Nepali Sign Language (NSL) gestures into\\ncorresponding Nepali text format. The system utilizes computer vision and deep learning techniques, specifically a Convolutional\\nNeural Network (CNN) model trained on a dataset of over 2,500 images per label with total of 50 labels. The training accuracy was'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Neural Network (CNN) model trained on a dataset of over 2,500 images per label with total of 50 labels. The training accuracy was\\n99%, whereas the validation accuracy was 87.78%. Training loss settled at 1.18%, and validation loss settled at 8.258%. A dropout\\nlayer and early stopping function were introduced, and the model was trained for 50 epochs. The model achieved training accuracy\\nof 99.84% and validation accuracy of 99.80%. Similarly, model Training Loss was 0.6% and Validation Loss was 1.16%. The\\nAccuracy curve showed that the both validation and training accuracy gradually increased to 90% for 10 epochs and became steady.\\nSimilarly,in Loss curve both validation and training loss gradually decreased to 4% over the course of 10 epochs and stabilized. A\\nClassification table was created using 20% of total dataset with 500 for each label. Model performance was exceptional for most of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Classification table was created using 20% of total dataset with 500 for each label. Model performance was exceptional for most of\\nthe labels achieving precision, recall and F1-score close to 1. However,for some labels ,model performance was lower in terms of\\nprecision (less than 0.98). The overall accuracy of model was 0.99 describing that model perform well on the entire dataset. The\\ntrained model was integrated into a user-friendly web application along with the logic for finger spelling to verify and validate the real\\nlife use case of the research.\\nKeywords\\nNepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe\\n1. Introduction\\nSign language is an expressive form of communication used\\nby individuals who are deaf or hard of hearing. It allows them\\nto convey thoughts, ideas, and emotions through manual\\ngestures, facial expressions, and body movements. However,\\ndeaf individuals often encounter significant barriers in their'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='to convey thoughts, ideas, and emotions through manual\\ngestures, facial expressions, and body movements. However,\\ndeaf individuals often encounter significant barriers in their\\ndaily interactions, primarily due to the difficulty of\\ncommunicating with those who do not understand sign\\nlanguage.\\nThere are numerous sign languages, such as American Sign\\nLanguage, Indian Sign Language, Nepalese Sign Language, and\\nso on. The signs used in these sign languages are not all the\\nsame. In our country, Nepal, various organizations and schools\\nhave been assisting deaf people to learn Nepali sign language.\\nUnderstanding the importance of connecting the deaf and\\nhearing communities, multiple technologies aimed at\\nimproving communication using Nepalese Sign Language for\\npersons who are deaf or hard of hearing were studied. It was\\nfound that there weren’t any specialized sources online\\nregarding Nepalese Sign Language (NSL). As a result, we\\naimed to create a model that would translate the NSL into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='found that there weren’t any specialized sources online\\nregarding Nepalese Sign Language (NSL). As a result, we\\naimed to create a model that would translate the NSL into\\ntextual output. The user will provide input via webcam, and\\nthe model can detect the hand gesture and output the\\nword/alphabet that the user provided as input to the model.\\nThis paper shows a model that can detect 47 Nepali Alphabets,\\n2 symbols, and one blank. The paper proposes the use of a\\nConvolution Neural Network (CNN). The paper present the\\nuse of Google’ s MediaPipe which is a Framework for building\\nmachine learning pipelines. With the help of MediaPipe Hand\\nModel Model, detect hand region and extract keypoints from\\nthe hands.\\n2. Literature Review\\nSign language is a crucial communication mode for the deaf\\nand hard-of-hearing community. Automatic sign language\\nrecognition (SLR) systems have the potential to bridge the\\ncommunication gap between these communities and the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='and hard-of-hearing community. Automatic sign language\\nrecognition (SLR) systems have the potential to bridge the\\ncommunication gap between these communities and the\\nhearing world. This review focuses on recent advancements in\\nvideo-based SLR systems that leverage deep learning\\ntechniques, particularly Convolutional Neural Networks\\n(CNNs) and Long Short-Term Memory (LSTM) networks.\\nRecent literature in sign language recognition highlights a\\ntransformative shift towards deep learning methodologies,\\nparticularly evident in a pivotal study on Nepali Sign\\nLanguage [ 1]. Deep learning is applied for both motion\\ndetection and detailed exploration of gestures, extracting\\nspatial and temporal features. Two approaches are explored:\\none using CNN and RNN, and another using CNN and Vision\\nTransformer. The latter outperforms in accuracy, emphasizing\\nthe growing importance of deep learning in enhancing sign\\nlanguage recognition systems. These advancements'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 0, 'page_label': '166'}, page_content='Transformer. The latter outperforms in accuracy, emphasizing\\nthe growing importance of deep learning in enhancing sign\\nlanguage recognition systems. These advancements\\ncontribute to improved communication accessibility for\\nindividuals relying on sign language.\\nPages: 166 – 170'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='Proceedings of 15th IOE Graduate Conference\\nFigure 1: System Block Diagram\\nExpanding on this foundation, another significant\\ncontribution emerged in the form of a novel method for\\ncharacter identification in American Sign Language, utilizing\\nConvolutional Neural Networks (CNNs) [2]. The research not\\nonly introduced an innovative approach but also emphasized\\nthe indispensable role CNNs play in the realm of sign\\nlanguage recognition, particularly in the context of character\\nidentification. The implications of this study extend beyond\\nAmerican Sign Language, shaping the trajectory of gesture\\nrecognition in a broader spectrum.\\nDiversifying the research landscape, a study concentrating on\\nIndian Sign Language harnessed the capabilities of MediaPipe\\nHolistic to identify movements and facilitate their conversion\\ninto text or voice, effectively bridging the communication gap\\nbetween sign language and other modes of expression [ 3].\\nNoteworthy is the emphasis on discerning between static and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='into text or voice, effectively bridging the communication gap\\nbetween sign language and other modes of expression [ 3].\\nNoteworthy is the emphasis on discerning between static and\\ndynamic signs, revealing the superior performance of Long\\nShort-Term Memory (LSTM) models in tracking dynamic\\nphrases, while CNNs demonstrate proficiency in capturing\\nstatic characters.\\nIn parallel, a groundbreaking project introduced a real-time\\nsign language detection system by synergizing Convolutional\\nNeural Networks (CNNs) and Recurrent Neural Networks\\n(RNNs) [ 4]. The study, titled \"Recognizing Sign Language\\nGestures from Video Sequences,\" showcased the synergistic\\neffectiveness of these networks in real-time recognition,\\nsetting the stage for practical applications in assistive\\ntechnology.\\nLastly, Research Journal of Engineering and Technology The\\nproposed system integrates Convolutional Neural Networks\\n(CNNs) for visual feature extraction and Long Short-Term'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='technology.\\nLastly, Research Journal of Engineering and Technology The\\nproposed system integrates Convolutional Neural Networks\\n(CNNs) for visual feature extraction and Long Short-Term\\nMemory (LSTM) networks for understanding the order of\\nsigns [5]. The primary objective was to convert Nepali Sign\\nLanguage into written text. The system captures sign images\\nthrough a camera and employs a CNN to analyze them. Initial\\ntraining concentrated on a limited set of signs (5 and 7), with\\nbetter accuracy achieved in the smaller set. Despite promising\\noutcomes, the study acknowledges constraints, such as a\\nrestricted sign vocabulary and reliance on red gloves during\\ntesting, posing challenges for practical use. In essence, this\\nresearch represents a crucial step in utilizing advanced neural\\nnetworks to enhance communication between the deaf and\\nhearing communities in Nepal.\\nIn summation, the collective body of research signifies the\\nascendance of deep learning, particularly the integration of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='hearing communities in Nepal.\\nIn summation, the collective body of research signifies the\\nascendance of deep learning, particularly the integration of\\nCNNs and LSTMs, in the realm of sign language recognition.\\nThese studies, encompassing diverse aspects from\\nunderstanding intricate gestures to real-time detection, depict\\na vibrant landscape of advancements that are actively shaping\\nthe future of communication for the hearing-impaired. The\\nintegration of deep learning not only ensures more accurate\\nand responsive gesture recognition systems but also holds the\\npromise of seamlessly incorporating sign languages into\\nmainstream communication technologies.\\n3. Methodology\\n3.1 Data Collection\\nImage datasets were captured using 4 different laptops for 50\\nlabels with an image resolution of 540 x 540 pixels. With the\\nhelp of the OpenCV library, the image was captured for about\\n2500 images per label; in total, 1,25,000 image datasets were'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 1, 'page_label': '167'}, page_content='labels with an image resolution of 540 x 540 pixels. With the\\nhelp of the OpenCV library, the image was captured for about\\n2500 images per label; in total, 1,25,000 image datasets were\\ncollected. These captured images were not the final dataset,\\nthe aim was to create a dataset containing Hand landmarks\\nfor these images. The sample image of the Captured Image is\\nshown in Figure 2.\\nFigure 2: Original Image\\n3.1.1 Cropping Capture Image\\nMediaPipe Hands Model used to crop the image, which is\\ndeveloped by Google to utilizes an ML pipeline consisting of\\n167'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN\\nmultiple models working together: A palm detection model\\nthat operates on the full image and returns an oriented hand\\nbounding box and a hand landmark model that operates on\\nthe cropped image region defined by the palm detector and\\nreturns high-fidelity 3D hand keypoints[6] as shown in Figure\\n3.\\nThe image with resolution 540 x 540 px was passed through\\nthe MediaPipe hand model with parameter static_image\\nmode = True, min_detection_confidence=0.3, and\\nmax_num_hands=1 to detect the palm area from the captured\\nimage. Before being fed to the Hand landmark model, the\\nimage is converted into RBG format. Using this model, a set of\\n21 key points representing various landmarks on the hand was\\nobtained, such as fingertips, knuckles, and the palm. Based on\\nthe Hand Landmark index 9 i.e MIDDLE FINGER MCP and\\nHand Landmark index 12 i.e. MIDDLE FINGER TIP , the\\noriginal image was cropped. The size of the cropped image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='the Hand Landmark index 9 i.e MIDDLE FINGER MCP and\\nHand Landmark index 12 i.e. MIDDLE FINGER TIP , the\\noriginal image was cropped. The size of the cropped image\\nwas set to 200 x 200 pixels, determined by the original\\ndimensions of the image. These cropped images contain only\\nthe image of one palm or hand, which is in BGR form. The\\nsample of the cropped image is shown in figure 4. This\\ncropped image contained only the palm area image not a\\nHand Keypoints.\\nFigure 3: Hand Landmark\\n3.1.2 Hand Landmark Image Drawing\\nThe cropped image was converted into RGB form and fed to\\nMediaPipe Hand model to extract key points of hand from the\\ncropped images. Based on the coordinates of the extracted key\\npoints, the coordinates of landmarks were drawn on the plain\\nblack background. The drawn hand landmark image had the\\nsame shape as the cropped images i.e. 200 x 200 pixels. The\\nlandmark image was saved in grayscale format. The sample\\nimage of the Landmark image is shown in figure 5. This Hand'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='same shape as the cropped images i.e. 200 x 200 pixels. The\\nlandmark image was saved in grayscale format. The sample\\nimage of the Landmark image is shown in figure 5. This Hand\\nLandmark Image was the final Dataset. Each Character of the\\nNepali Alphabet was labeled as shown in figure 6.\\nFigure 4: Cropped Image\\n Figure 5: Landmark Image\\nFigure 6: Dataset Label\\n3.2 Data Pre-Processing\\nDuring pre-processing, the dataset image was converted into\\na NumPy array and reshaped to 200 x 200 pixels. The pixel\\nvalues lie within a range of 0 to 1 in this preprocessed image\\ndata, which comprises a 4D NumPy array.\\n3.3 Training CNN Model\\nThe training process focused on instructing the model to\\nidentify Nepali Sign Language (NSL) signs from video frames\\nof gestures. Initially, 125,000 total dataset were divided into\\ntraining and validation sets with an 80-20 ratio using the split\\nfolders library i.e. Training set consists of 100,000 dataset and\\nthe Validation or Test set consists of 25,000 dataset.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='training and validation sets with an 80-20 ratio using the split\\nfolders library i.e. Training set consists of 100,000 dataset and\\nthe Validation or Test set consists of 25,000 dataset.\\nImageDataGenerator was employed with an input size of\\n200*200, class mode set to ‘categorical’ , color mode set to\\n‘grayscale’ , and a batch size of 128. This was utilized to convert\\nthe data into the necessary format and normalize the dataset\\nusing the rescale parameter.\\nIn order to include all required layers, the model’ s architecture\\ncontained a sequential Keras model. At first, features were\\nextracted from the video frame using Conv2D layers with a 3x3\\nkernel and the ‘relu’ activation function. The MaxPooling2D\\nlayers with a 2x2 filter were applied before each Conv2D layer,\\nallowing for a reduction in both image size and complexity. To\\nreduce overfitting, dropout layers with a 0.4 dropout rate were\\nalso included. To improve the model’ s compatibility, these'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='allowing for a reduction in both image size and complexity. To\\nreduce overfitting, dropout layers with a 0.4 dropout rate were\\nalso included. To improve the model’ s compatibility, these\\nthree layers were replicated. The 4D data was then\\ntransformed into 1D using a flatten layer. ‘Relu’ activation\\nfunctions were used in two Dense layers, with 256 and 64\\nchannels, respectively. The final classification of NSL signs\\nwas given to a Dense layer with 50 output channels and\\nsoftmax activation.\\nTo compile the model, the Adam optimizer with a default\\nlearning rate of 0.001 was employed. Other optimizers, such\\nas SGD with a learning rate of 0.01 and RMSProp with a\\nlearning rate of 0.001, were also tested, but Adam was found to\\nbe the best fit for the model. To find the optimal parameter,\\nthe learning rate of Adam was further revised, with values\\nranging from 0.0001, 0.002, and 0.0002, but the default Adam\\nsetting turned out to be the most accurate. For the loss'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 2, 'page_label': '168'}, page_content='the learning rate of Adam was further revised, with values\\nranging from 0.0001, 0.002, and 0.0002, but the default Adam\\nsetting turned out to be the most accurate. For the loss\\nfunction, Categorical Cross-Entropy was utilized. Additionally,\\naccuracy was used as a statistic to evaluate how well the\\nmodel predicted NSL signals. The model was then trained\\nusing the fit function, which was used to select the number of\\nepochs and incorporate the validation set to measure\\nperformance throughout the process. The validation loss was\\n168'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='Proceedings of 15th IOE Graduate Conference\\nanalyzed using the EarlyStopping function, which was used to\\nend the fitting process when suitable. Finally, the accuracy of\\nthe model was evaluated to measure its effectiveness.\\n3.4 Model Integration with Logic for Finger Spelling\\nA straightforward approach was developed to combine letters\\ndetected by a CNN model for Nepali finger spelling. Letters\\nare stored in an array, and once the array is full and contains at\\nleast two letters, they are processed to form a complete word.\\nThe system differentiates between consonants and vowels,\\napplying specific logic based on their combinations.\\nVowel-vowel pairs are simply joined, while consonant-vowel\\ncombinations involve replacing the vowel with its\\ncorresponding symbol as shown in figure 7 and joining it with\\nthe consonant. In both vowel-consonant and\\nconsonant-consonant combinations, the initial part (or the\\nfirst letter in the array) remains unchanged. The process then'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='the consonant. In both vowel-consonant and\\nconsonant-consonant combinations, the initial part (or the\\nfirst letter in the array) remains unchanged. The process then\\nfocuses on modifying the second consonant based on the\\nfollowing letter (third letter in the array for any of the above\\ncombinations). This logic ensures proper Nepali word\\nformation by considering the unique characteristics of\\nconsonant-vowel interactions in the language.\\nFigure 7: Vowel and Their Symbol\\n4. Results and Discussion\\n4.1 Result\\n4.1.1 Accuracy and Loss Curve\\nThe accuracy curve shown in figure 8 rapidly increases to\\nnearly 100%, indicating how well the model fits the training set\\nof data. However, the validation accuracy curve peaks around\\n90% after an initial sharp rise. This indicates that the model\\ndoes not get any more accurate with more training epochs,\\nbut it does generalize to unknown data very well initially.\\nFigure 8: Accuracy Curve\\n Figure 9: Loss Curve'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='does not get any more accurate with more training epochs,\\nbut it does generalize to unknown data very well initially.\\nFigure 8: Accuracy Curve\\n Figure 9: Loss Curve\\nSimilarly, the Loss Curve shown in figure 9 drops sharply to\\nnear zero within the first few epochs. This confirms the model\\nfits the training data extremely well after initial learning.\\nHowever, the validation loss curve initially decreases and then\\npeaks at a higher value compared to the training loss. This\\nindicates the model is being overfitted to the training data.\\nThis limits the model’ s ability to generalize and perform well\\non new, unseen data from the validation set.\\n4.1.2 Classification Table\\nprecision recall f1-score support\\n0 0.98 1.00 0.99 500\\n1 0.97 0.99 0.98 500\\n2 0.99 0.93 0.96 500\\n3 0.99 1.00 0.99 500\\n4 1.00 0.99 0.99 500\\n5 1.00 1.00 1.00 500\\n6 1.00 1.00 1.00 500\\n7 1.00 1.00 1.00 500\\n8 1.00 0.99 0.99 500\\n9 0.99 0.99 0.99 500\\n10 0.98 1.00 0.99 500\\n11 0.99 1.00 1.00 500\\n12 1.00 1.00 1.00 500'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='4 1.00 0.99 0.99 500\\n5 1.00 1.00 1.00 500\\n6 1.00 1.00 1.00 500\\n7 1.00 1.00 1.00 500\\n8 1.00 0.99 0.99 500\\n9 0.99 0.99 0.99 500\\n10 0.98 1.00 0.99 500\\n11 0.99 1.00 1.00 500\\n12 1.00 1.00 1.00 500\\n13 0.99 0.98 0.98 500\\n14 0.98 0.98 0.98 500\\n15 0.99 0.98 0.99 500\\n16 0.99 1.00 1.00 500\\n17 0.98 1.00 0.99 500\\n18 1.00 0.99 0.99 500\\n19 0.96 0.99 0.97 500\\n20 1.00 1.00 1.00 500\\n21 0.97 1.00 0.99 500\\n22 0.99 1.00 0.99 500\\n23 1.00 1.00 1.00 500\\n24 0.99 0.96 0.98 500\\n25 1.00 0.99 0.99 500\\n26 1.00 1.00 1.00 500\\n27 0.99 0.99 0.99 500\\n28 1.00 1.00 1.00 500\\n29 0.97 0.99 0.98 500\\n30 0.99 0.99 0.99 500\\n31 1.00 1.00 1.00 500\\n32 1.00 0.99 0.99 500\\n33 1.00 1.00 1.00 500\\n34 1.00 1.00 1.00 500\\n35 1.00 0.97 0.98 500\\n36 0.99 1.00 0.99 500\\n37 1.00 1.00 1.00 500\\n38 0.97 1.00 0.99 500\\n39 0.98 1.00 0.99 500\\n40 1.00 1.00 1.00 500\\n41 1.00 1.00 1.00 500\\n42 1.00 1.00 1.00 500\\n43 1.00 0.99 1.00 500\\n44 1.00 1.00 1.00 500\\n45 1.00 0.97 0.98 500\\n46 0.99 0.98 0.99 500\\n47 1.00 1.00 1.00 500\\n48 0.98 0.97 0.97 500'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 3, 'page_label': '169'}, page_content='40 1.00 1.00 1.00 500\\n41 1.00 1.00 1.00 500\\n42 1.00 1.00 1.00 500\\n43 1.00 0.99 1.00 500\\n44 1.00 1.00 1.00 500\\n45 1.00 0.97 0.98 500\\n46 0.99 0.98 0.99 500\\n47 1.00 1.00 1.00 500\\n48 0.98 0.97 0.97 500\\n49 0.98 0.98 0.98 500\\naccuracy 0.99 25000\\nmacro avg 0.99 0.99 0.99 25000\\nweighted avg 0.99 0.99 0.99 25000\\nA classification report is a comprehensive summary of the\\nperformance of a classification algorithm on a dataset. It\\nprovides various metrics for each class, helping to evaluate the\\nmodel’ s precision, recall, F1 score, and support. The\\nclassification Table of our model is shown in the above Table.\\n169'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN\\n4.1.3 Output\\nFigure 10: Hand Landmark Detection Steps\\nFigure 11: Output\\nFigure 11 shows the real time prediction of a letter and joining\\nof each letter to form a word at last.\\nFigure 12: Success Case\\nHand gesture is detected and landmark is successfully drawn,\\nbut only when the hand is shown to the camera at the right\\nangle, at about 60 cm from the camera, the hand must be held\\nstable, and the signs must only be given according to prompts\\ndisplayed on the screen.\\nFigure 13: Change in\\nAngle\\n Figure 14: Low Light\\nHand might not be detected properly if it’ s too close to the\\ncamera or if it’ s not facing directly towards the camera.\\nChanges in lighting can also affect detection. In case of wrong\\nhand gesture input, it might give the wrong output.\\n5. Conclusion\\nThe majority of the deaf community faces deprivation of basic\\nservices due to communication barriers with the hearing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='hand gesture input, it might give the wrong output.\\n5. Conclusion\\nThe majority of the deaf community faces deprivation of basic\\nservices due to communication barriers with the hearing\\ncommunity. This paper introduced a model designed to\\npredict Nepali Sign language characters. Mediapipe and\\nOpenCV were used for Real-time data collection.\\nModel-building strategies like transfer learning and different\\nneural network architectures were examined and a simple\\nCNN model which contained ConV2D, MaxPolling layer,\\nFlatten layer, and Dense layer, was ultimately chosen.\\nOptimizers like ‘ Adam’ , ‘RMSProp’ , and ‘SGD’ were examined,\\nleading to the selection of Adam optimizers. A graph was\\nanalyzed by changing the learning rate to 0.0001, 0.002, 0.0002,\\netc. However, the default ‘ Adam’ worked accurately for the\\nmodel. At first, Relu activation function was used in all layers\\nincluding the output Dense layer. The Accuracy and Loss\\ncurve were steady. Finally Softmax activation function was'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='model. At first, Relu activation function was used in all layers\\nincluding the output Dense layer. The Accuracy and Loss\\ncurve were steady. Finally Softmax activation function was\\nused which provided the appropriate graph with accuray of\\n99%˙The model’ s advancement to produce words directly\\ninstead of only characters is a crucial step toward its future\\ndevelopment. The model needs to be improved for real-time\\nprocessing speed in order for its use to be expanded beyond\\nprimary school students. Furthermore, adding extra features\\nlike captioning for sign language videos can significantly\\nimprove inclusion and accessibility. All of these improvements\\nwork together to improve the model’ s performance and\\nincrease the range of educational levels and communication\\nmodalities in which it can be used.\\nAcknowledgments\\nThe authors extend their heartfelt gratitude to the Department\\nof Electronics and Computer Engineering, Purwanchal\\nCampus for the unwavering support, guidance, and\\nencouragement.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Acknowledgments\\nThe authors extend their heartfelt gratitude to the Department\\nof Electronics and Computer Engineering, Purwanchal\\nCampus for the unwavering support, guidance, and\\nencouragement.\\nReferences\\n[1] S. Ligal and D. S. Baral. Nepali sign language gesture\\nrecognition using deep learning. In Proceedings of the 12th\\nIOE Graduate Conference, volume 12, October 2022.\\n[2] Sarfaraz Masood, Harish Chandra Thuwal, and Adhyan\\nSrivastava. American sign language character recognition\\nusing convolution neural network. In Smart Computing\\nand Informatics, pages 403–412. Springer, 2018.\\n[3] Kaushal Goyal and Dr. Velmathi G. Indian sign language\\nrecognition using mediapipe holistic. In Proceedings of the\\nVIT, Chennai, India, 2023.\\n[4] Sarfaraz Masood, Adhyan Srivastava, Harish Chandra\\nThuwal, and Musheer Ahmad. Real-time sign language\\ngesture (word) recognition from video sequences using\\ncnn and rnn. In Intelligent Engineering Informatics, pages\\n623–632. Springer, 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-08-22T12:54:44+05:45', 'author': 'Guptaraj Shrestha, Nishan Thing, Prajita Dhakal, Prasanga Dahal, Pukar Karki, Manoj Kumar Guragain', 'title': 'Nepali Sign Language Letter Detection and Finger Spelling Using Mediapipe and CNN', 'subject': '14th IOE Graduate Conference', 'keywords': 'Nepali Sign Language, Machine Learning, Convolutional Neural Network, MediaPipe', 'moddate': '2024-08-22T12:54:44+05:45', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'research.pdf', 'total_pages': 5, 'page': 4, 'page_label': '170'}, page_content='Thuwal, and Musheer Ahmad. Real-time sign language\\ngesture (word) recognition from video sequences using\\ncnn and rnn. In Intelligent Engineering Informatics, pages\\n623–632. Springer, 2018.\\n[5] D. Mali, R. Mali, S. Sipai, and S. P . Pandey. Nepali sign\\nlanguage translation using convolutional neural network.\\nIn 1st KEC Conference Proceedings, Volume I, September 27\\n2018.\\n[6] MediaPipe. Mediapipe hands documentation, 2024.\\n170')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ffe4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x18b6fafc2f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "llm= OllamaEmbeddings(model=\"mistral\")\n",
    "\n",
    "db=FAISS.from_documents(docs,llm)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76873ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Give the correct answer to the question based on the context provided.\n",
    "    think step by step and provide the final answer.\n",
    "    if answer is correct i will give 5 start rating to you.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Question:{input}\n",
    "    \"\"\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55d30434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\n    Give the correct answer to the question based on the context provided.\\n    think step by step and provide the final answer.\\n    if answer is correct i will give 5 start rating to you.\\n    <context>\\n    {context}\\n    </context>\\n    Question:{input}\\n    '), additional_kwargs={})])\n",
       "| Ollama(model='mistral')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.llms import Ollama\n",
    "model = Ollama(model=\"mistral\")\n",
    "document_chain = create_stuff_documents_chain(llm=model, prompt=prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9e9e28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000018B6FAFC2F0>, search_kwargs={'k': 1})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_db = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "retriever_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63531579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain =create_retrieval_chain(\n",
    "    retriever_db,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3e75c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The main focus of the research paper is on developing a CNN model to identify Nepali Sign Language (NSL) signs from video frames of gestures. This is inferred from the context provided, as it mentions that the training process is focused on this task and the dataset used for this purpose is a Hand Landmark Image of the Nepali alphabet.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =retrieval_chain.invoke({\"input\": \"What is the main focus of the research paper?\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de280b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
